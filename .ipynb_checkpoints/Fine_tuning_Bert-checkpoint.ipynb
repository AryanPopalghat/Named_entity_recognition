{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc72e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets tokenizers seqeval -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9229245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import datasets\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, DataCollatorForTokenClassification, AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import json\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74622fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CoNLL 2003 NER dataset\n",
    "conll2003 = datasets.load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b692411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84a2d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (14041, 5), 'validation': (3250, 5), 'test': (3453, 5)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c45ea82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1409588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1307055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conll2003['train'].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29642471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad0b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below cell are just for checking the output of some variables before applying `tokenize_and_align_labels()`\n",
    "example_text = conll2003['train'][0]\n",
    "\n",
    "tokenized_input = tokenizer(example_text[\"tokens\"], is_split_into_words=True)\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "word_ids = tokenized_input.word_ids()\n",
    "\n",
    "print(word_ids)\n",
    "\n",
    "''' As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. '''\n",
    "\n",
    "tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cbd060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The  input ids returned by the tokenizer are longer than the lists of labels our dataset contain.\n",
    "len(example_text['ner_tags']), len(tokenized_input[\"input_ids\"])\n",
    "# (9, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f88427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and align labels with tokens\n",
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    # Function to tokenize and align labels with tokens\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Set special tokens' labels to -100\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])  # Set label of the first token of a word\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)  # Mask subwords\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be771e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}\n"
     ]
    }
   ],
   "source": [
    "q = tokenize_and_align_labels(conll2003['train'][4:5]) \n",
    "print(q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "977cb23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________ -100\n",
      "germany_________________________________ 5\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "representative__________________________ 0\n",
      "to______________________________________ 0\n",
      "the_____________________________________ 0\n",
      "european________________________________ 3\n",
      "union___________________________________ 4\n",
      "'_______________________________________ 0\n",
      "s_______________________________________ 0\n",
      "veterinary______________________________ 0\n",
      "committee_______________________________ 0\n",
      "werner__________________________________ 1\n",
      "z_______________________________________ 2\n",
      "##wing__________________________________ 2\n",
      "##mann__________________________________ 2\n",
      "said____________________________________ 0\n",
      "on______________________________________ 0\n",
      "wednesday_______________________________ 0\n",
      "consumers_______________________________ 0\n",
      "should__________________________________ 0\n",
      "buy_____________________________________ 0\n",
      "sheep___________________________________ 0\n",
      "##me____________________________________ 0\n",
      "##at____________________________________ 0\n",
      "from____________________________________ 0\n",
      "countries_______________________________ 0\n",
      "other___________________________________ 0\n",
      "than____________________________________ 0\n",
      "britain_________________________________ 5\n",
      "until___________________________________ 0\n",
      "the_____________________________________ 0\n",
      "scientific______________________________ 0\n",
      "advice__________________________________ 0\n",
      "was_____________________________________ 0\n",
      "clearer_________________________________ 0\n",
      "._______________________________________ 0\n",
      "[SEP]___________________________________ -100\n"
     ]
    }
   ],
   "source": [
    "# Before applying the `tokenize_and_align_labels()` the `tokenized_input` has 3 keys \n",
    "# - input_ids\n",
    "# - token_type_ids\n",
    "# - attention_mask\n",
    "\n",
    "# But after applying `tokenize_and_align_labels()` we have an extra key - `'labels'`\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]),q[\"labels\"][0]): \n",
    "    print(f\"{token:_<40} {label}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb33e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenization and alignment to the dataset\n",
    "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc15187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model for token classification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e243fa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (22.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "834526fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.31.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2023.8.8)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (4.64.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256af988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "args = TrainingArguments(\n",
    "    \"test-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e18492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5235fe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\ipykernel_16404\\2246954560.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "# Load metrics for evaluation\n",
    "metric = datasets.load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69e7bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = conll2003['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8098f423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names \n",
    "\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58df2cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[\"ner_tags\"]] \n",
    "\n",
    "metric.compute(predictions=[labels], references=[labels]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dcdebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics function\n",
    "def compute_metrics(eval_preds):\n",
    "    pred_logits, labels = eval_preds\n",
    "    pred_logits = np.argmax(pred_logits, axis=2)\n",
    "    predictions = [\n",
    "        [label_list[pred] for (pred, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (pred, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(pred_logits, labels)\n",
    "    ]\n",
    "    results = metric.compute(predictions=predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3600f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c68da4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5268/5268 6:05:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.061235</td>\n",
       "      <td>0.915701</td>\n",
       "      <td>0.936906</td>\n",
       "      <td>0.926182</td>\n",
       "      <td>0.982811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.933828</td>\n",
       "      <td>0.944065</td>\n",
       "      <td>0.938919</td>\n",
       "      <td>0.985782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.060713</td>\n",
       "      <td>0.939736</td>\n",
       "      <td>0.948988</td>\n",
       "      <td>0.944339</td>\n",
       "      <td>0.986544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5268, training_loss=0.06612263734175929, metrics={'train_runtime': 21936.0521, 'train_samples_per_second': 1.92, 'train_steps_per_second': 0.24, 'total_flos': 895125623975100.0, 'train_loss': 0.06612263734175929, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "080524dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.txt',\n",
       " 'tokenizer\\\\added_tokens.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"ner_model\")\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "469d3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save id-to-label and label-to-id mappings\n",
    "id2label = {str(i): label for i, label in enumerate(label_list)}\n",
    "label2id = {label: str(i) for i, label in enumerate(label_list)}\n",
    "\n",
    "config = json.load(open(\"ner_model/config.json\"))\n",
    "config[\"id2label\"] = id2label\n",
    "config[\"label2id\"] = label2id\n",
    "json.dump(config, open(\"ner_model/config.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a016e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7873a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.6'\n"
     ]
    }
   ],
   "source": [
    "# Create an NER pipeline using the fine-tuned model and tokenizer\n",
    "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a44fb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text for NER\n",
    "example = \"Bill Gates is the Founder of Microsoft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93a350ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9946613, 'index': 1, 'word': 'bill', 'start': 0, 'end': 4}, {'entity': 'I-PER', 'score': 0.99673957, 'index': 2, 'word': 'gates', 'start': 5, 'end': 10}, {'entity': 'B-ORG', 'score': 0.9900035, 'index': 7, 'word': 'microsoft', 'start': 29, 'end': 38}]\n"
     ]
    }
   ],
   "source": [
    "# Perform NER\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dedb37f",
   "metadata": {},
   "source": [
    "O means the word doesnâ€™t correspond to any entity. <br>\n",
    "B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity. <br>\n",
    "B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.<br>\n",
    "B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.<br>\n",
    "B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9aad7",
   "metadata": {},
   "source": [
    "### Launching Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a243e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.40.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: aiohttp~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.101.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.12.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.6.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (22.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.5.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client>=0.4.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (2022.12.7)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (0.17.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.2)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26d04866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.8.2\n",
      "  Using cached pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic==1.8.2) (4.7.1)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.2.1\n",
      "    Uninstalling pydantic-2.2.1:\n",
      "      Successfully uninstalled pydantic-2.2.1\n",
      "Successfully installed pydantic-1.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydantic==1.8.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "571e709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.40.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: aiohttp~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.101.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.24.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.16.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.12.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.6.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (22.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.5.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.28.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.7.1)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.23.2)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client>=0.4.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.64.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests~=2.0->gradio) (2022.12.7)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (0.17.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=7.0->uvicorn>=0.14.0->gradio) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.2)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.2)\n",
      "Collecting pydantic\n",
      "  Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/fd/35/86b1e7571e695587df0ddf2937100436dce0caa277d2f016d4e4f7d3791a/pydantic-2.2.1-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.2.1-py3-none-any.whl.metadata (145 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic) (4.7.1)\n",
      "Using cached pydantic-2.2.1-py3-none-any.whl (373 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "Successfully installed pydantic-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio -U\n",
    "!pip install pydantic -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58a11e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypeAlias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d2f668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.7.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " pip install typing-extensions --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3cb25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54c1f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, BertTokenizerFast, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b56e6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27ba4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an NER pipeline using the fine-tuned model and tokenizer\n",
    "nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed0b4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that performs NER using the fine-tuned model\n",
    "def named_entity_recognition(text_input):\n",
    "    ner_results = nlp(text_input)\n",
    "    return ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a460f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Temp\\ipykernel_16404\\2774139770.py:4: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Textbox(),  # Text input component\n",
      "c:\\Temp\\ipykernel_16404\\2774139770.py:4: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(),  # Text input component\n",
      "c:\\Temp\\ipykernel_16404\\2774139770.py:4: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Textbox(),  # Text input component\n",
      "c:\\Temp\\ipykernel_16404\\2774139770.py:5: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs=gr.outputs.Textbox()  # Text output component\n"
     ]
    }
   ],
   "source": [
    "# Create a Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=named_entity_recognition,\n",
    "    inputs=gr.inputs.Textbox(),  # Text input component\n",
    "    outputs=gr.outputs.Textbox()  # Text output component\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1415af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "Running on public URL: https://acb84f1afb5817dedd.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://acb84f1afb5817dedd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the Gradio interface\n",
    "iface.launch(share='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282966d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
